{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews,stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.classify import ClassifierI\n",
    "\n",
    "from statistics import mode\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "# nltk.download('movie_reviews')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words(\"English\"))\n",
    "# adding unnecessary signs and symbols\n",
    "for i in range(0,256):\n",
    "    stop_words.add(chr(i))\n",
    "\n",
    "# category( pos/neg )\n",
    "documents = []\n",
    "\n",
    "# pickle this shit\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        word_list = list(movie_reviews.words(fileid))\n",
    "        check_list = []\n",
    "        for word in word_list:\n",
    "            if word not in stop_words and not word.isdigit():\n",
    "                check_list.append(word)\n",
    "        documents.append((check_list,category))\n",
    "\n",
    "# print(documents[0])\n",
    "\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "\n",
    "for words in movie_reviews.words():\n",
    "\tall_words.append(words.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\t\t# most_common -> least_common\n",
    "\n",
    "# print(all_words.most_common(15))\n",
    "print(all_words[\"stop\"])\n",
    "\n",
    "words_features = list(all_words.keys())[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "def find_features(docum):\n",
    "\twords = set(docum)\n",
    "\tfeatures = {}\n",
    "\tfor word in words_features:\n",
    "\t\tfeatures[word] = word in words\n",
    "\treturn features\n",
    "\n",
    "# print(find_features(movie_reviews.words('neg/cv000_29416.txt')))\n",
    "feature_sets = [(find_features(rev),category) for (rev,category) in documents]\n",
    "\n",
    "print(len(feature_sets))\n",
    "\n",
    "training_set = feature_sets[:1900]    \n",
    "testing_set  = feature_sets[1900:]  \n",
    "\n",
    "# Naive Bayes \n",
    "# print(training_set[:4])\n",
    "# posterior = (prior_occurrences x likelihood) / evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original NB accuracy:  83.0\n",
      "Most Informative Features\n",
      "               ludicrous = True              neg : pos    =     14.6 : 1.0\n",
      "               atrocious = True              neg : pos    =     11.0 : 1.0\n",
      "                    hers = True              pos : neg    =     10.4 : 1.0\n",
      "                   sucks = True              neg : pos    =     10.2 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.3 : 1.0\n",
      "              accessible = True              pos : neg    =      9.0 : 1.0\n",
      "                  annual = True              pos : neg    =      9.0 : 1.0\n",
      "               stupidity = True              neg : pos    =      9.0 : 1.0\n",
      "                 frances = True              pos : neg    =      8.4 : 1.0\n",
      "           unimaginative = True              neg : pos    =      8.3 : 1.0\n",
      "                  justin = True              neg : pos    =      8.3 : 1.0\n",
      "                 wasting = True              neg : pos    =      7.7 : 1.0\n",
      "                narrates = True              pos : neg    =      7.0 : 1.0\n",
      "                  regard = True              pos : neg    =      7.0 : 1.0\n",
      "                  coyote = True              neg : pos    =      7.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "# pickling\n",
    "# classifier_f = open('naiveBayes.pickle','rb')\n",
    "# classifier = pickle.load(classifier_f)\n",
    "# classifier_f.close()\n",
    "\n",
    "print(\"Original NB accuracy: \",nltk.classify.accuracy(classifier,testing_set)*100)\n",
    "classifier.show_most_informative_features(15)    # top 15 \n",
    "\n",
    "# save_classifier = open(\"naiveBayes.pickle\",'wb')\n",
    "# pickle.dump(classifier,save_classifier)\n",
    "# save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB_classifier accuracy percent: 84.0\n",
      "test classification:  pos\n",
      "test label : pos\n",
      "BernoulliNB_classifier accuracy percent: 84.0\n",
      "LogisticRegression_classifier accuracy percent: 87.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 89.0\n",
      "LinearSVC_classifier accuracy percent: 86.0\n",
      "NuSVC_classifier accuracy percent: 90.0\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "# print(testing_set[0])\n",
    "print(\"test classification: \",str(MNB_classifier.classify(testing_set[0][0])))\n",
    "print(\"test label :\",testing_set[0][1])\n",
    "\n",
    "#GNB_classifier = SklearnClassifier(GaussianNB())\n",
    "#GNB_classifier.train(training_set)\n",
    "#print(\"Gaussian NB accuracy: \",nltk.classify.accuracy(GNB_classifier,testing_set)*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "# SVC_classifier = SklearnClassifier(SVC())\n",
    "# SVC_classifier.train(training_set)\n",
    "# print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "# tweak these to get + - 10% accuracy difference \n",
    "# Note : redundancy in data sets consideration ( most common words may contain punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voted_classifier accuracy percent: 89.0\n",
      "Labeled test1 as:  pos\n",
      "Classification test1 :  pos\n",
      "Confidence :  1.0\n",
      "Labeled test2 as:  pos\n",
      "Classification test2 :  pos\n",
      "Confidence :  1.0\n",
      "Labeled test3 as:  pos\n",
      "Classification test3 :  pos\n",
      "Confidence :  1.0\n",
      "Labeled test4 as:  neg\n",
      "Classification test4 :  neg\n",
      "Confidence :  1.0\n"
     ]
    }
   ],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "\tdef __init__(self,*classifiers):\n",
    "\t\tself.classifiers = classifiers\n",
    "\t\n",
    "\tdef classify(self,features):\n",
    "\t\tvotes = []\n",
    "\t\tfor cls in self.classifiers:\n",
    "\t\t\tv = cls.classify(features)\n",
    "\t\t\tvotes.append(v)\n",
    "\t\treturn mode(votes)\n",
    "\t\n",
    "\tdef confidence(self,features):\n",
    "\t\tvotes = []\n",
    "\t\tfor cls in self.classifiers:\n",
    "\t\t\tv = cls.classify(features)\n",
    "\t\t\tvotes.append(v)\n",
    "\t\tchoice = votes.count(mode(votes))\n",
    "\t\tconfid = choice/len(votes)\n",
    "\t\treturn confid \n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(classifier,\n",
    "\t\t\t\t\t\t\t\tMNB_classifier,\n",
    "\t\t\t\t\t\t\t\tBernoulliNB_classifier,\n",
    "\t\t\t\t\t\t\t\tLogisticRegression_classifier,\n",
    "\t\t\t\t\t\t\t\tSGDClassifier_classifier,\n",
    "\t\t\t\t\t\t\t\tLinearSVC_classifier,\n",
    "\t\t\t\t\t\t\t\tNuSVC_classifier)\n",
    "\n",
    "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)\n",
    "\n",
    "print(\"Labeled test1 as: \",testing_set[0][1])\n",
    "print(\"Classification test1 : \",voted_classifier.classify(testing_set[0][0]))\n",
    "print(\"Confidence : \",voted_classifier.confidence(testing_set[0][0]))\n",
    "\n",
    "print(\"Labeled test2 as: \",testing_set[1][1])\n",
    "print(\"Classification test2 : \",voted_classifier.classify(testing_set[1][0]))\n",
    "print(\"Confidence : \",voted_classifier.confidence(testing_set[1][0]))\n",
    "\n",
    "print(\"Labeled test3 as: \",testing_set[2][1])\n",
    "print(\"Classification test3 : \",voted_classifier.classify(testing_set[2][0]))\n",
    "print(\"Confidence : \",voted_classifier.confidence(testing_set[2][0]))\n",
    "\n",
    "print(\"Labeled test4 as: \",testing_set[3][1])\n",
    "print(\"Classification test4 : \",voted_classifier.classify(testing_set[3][0]))\n",
    "print(\"Confidence : \",voted_classifier.confidence(testing_set[3][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}